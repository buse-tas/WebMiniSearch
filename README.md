# WebMiniSearch

A lightweight web search engine built with Python and Flask. It crawls a target website, indexes its content using Whoosh, and provides a simple search interface.

---

## Features

- Web crawler that follows internal links automatically
- Full-text indexing with Whoosh (with stemming support)
- Title-boosted ranking (title matches count 2x more than body matches)
- Simple Flask-based search UI
- Stop word removal and Porter stemming for better query matching

---

## Project Structure

```
WebMiniSearch/
│
├── crawler.py            # Crawls the target website and builds the index
├── query_parser.py       # Parses search queries and retrieves relevant pages
├── search_engine.py      # Flask web application
├── utils.py              # Utility functions (text cleaning, NLTK setup)
├── search.wsgi           # WSGI entry point for server deployment
├── requirements.txt      # Python dependencies
│
├── indexdir/             # Whoosh index (generated by crawler.py)
│
└── templates/
    ├── start.html            # Home / search page
    └── search_for_pages.html # Search results page
```

---

## Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/WebMiniSearch.git
   cd WebMiniSearch
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the crawler** (only needed if you want to rebuild the index)
   ```bash
   python crawler.py
   ```

4. **Start the Flask app**
   ```bash
   flask --app search_engine run
   ```

5. Open your browser and go to `http://127.0.0.1:5000`

---

## Configuration

| Environment Variable | Description | Default |
|---|---|---|
| `NLTK_DATA_DIR` | Custom directory for NLTK data files | System default |

Set it before running if needed:
```bash
export NLTK_DATA_DIR=/path/to/nltk_data
```

---

## Deployment (Apache + mod_wsgi)

Update the paths in `search.wsgi` to match your server's directory structure, then configure Apache to use it as the WSGI entry point.

---

## Dependencies

- [Flask](https://flask.palletsprojects.com/)
- [Whoosh](https://whoosh.readthedocs.io/)
- [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)
- [NLTK](https://www.nltk.org/)
- [Requests](https://requests.readthedocs.io/)

---

## Notes

- The `indexdir/` folder contains a pre-built index of the target website. You only need to re-run `crawler.py` if you want to re-crawl.
- The OpenAI-based page summarization feature is included in `crawler.py` but disabled by default (requires a valid API key).
